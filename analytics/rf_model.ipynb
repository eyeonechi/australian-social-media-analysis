{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ['SPARK_HOME'] = \"spark\"\n",
    "sys.path.append(\"spark/python\")\n",
    "sys.path.append(\"spark/python/lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get coordinates of a given city\n",
    "import httplib2\n",
    "import json\n",
    "\n",
    "\n",
    "def cityPos(name):\n",
    "    url = \"https://maps.googleapis.com/maps/api/geocode/json?\" + \\\n",
    "          \"key=AIzaSyBsZErhxaT1oVgMrT-xGLcAN5nK3UHeGBU&address=\" + name\n",
    "    req = httplib2.Http(\".cache\")\n",
    "    resp, content = req.request(url, \"GET\")\n",
    "    res = json.loads(content)\n",
    "    return res[\"results\"][0][\"geometry\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reform the data preparing for fitting the model\n",
    "import csv\n",
    "import json\n",
    "import codecs\n",
    "import time as t\n",
    "from couch import Couch\n",
    "\n",
    "#COUCHDB_NAME = \"cl_richard\"\n",
    "COUCHDB_NAME = \"classified1\"\n",
    "REFORMED_FILE = \"data/output0.csv\"\n",
    "\n",
    "food_dict = {}\n",
    "rev_dict = {}\n",
    "\n",
    "def trans(path):\n",
    "    con = Couch(COUCHDB_NAME)\n",
    "    jsonData = con.query_all()\n",
    "\n",
    "    csvfile = open(REFORMED_FILE, 'w', newline='')\n",
    "    writer = csv.writer(csvfile, delimiter=',', quoting=csv.QUOTE_ALL)\n",
    "    keys=['id', 'time', 'timestamp', 'lat', 'lng', 'polarity', 'followers', 'following', 'homeless', \\\n",
    "          'homeless_trend', 'food_class']\n",
    "    writer.writerow(keys)\n",
    "    \n",
    "    i = 0\n",
    "    for dic in jsonData:\n",
    "        # get coordinates\n",
    "        if dic['location']['coordinates'] is None:\n",
    "            city = dic['location']['place_name']\n",
    "            city = city.replace(\" \",\"%20\")\n",
    "            coor = cityPos(city)\n",
    "            lng = coor['location']['lng']\n",
    "            lat = coor['location']['lat']\n",
    "        else:\n",
    "            lng = dic['location']['coordinates'][0]\n",
    "            lat = dic['location']['coordinates'][1]\n",
    "            \n",
    "        # get time amd timesptamp\n",
    "        time = dic['created_at']['day']+'-'+trans_month(dic['created_at']['month'])+'-'+dic['created_at']['year']+\\\n",
    "                ' '+dic['created_at']['time']\n",
    "        timeArray = t.strptime(time, \"%d-%m-%Y %H:%M:%S\")\n",
    "        timestamp = t.mktime(timeArray)\n",
    "        \n",
    "        # to ensure at least one of homeless info and food info appears\n",
    "        home = dic['homeless']\n",
    "        foods = dic['food_list']\n",
    "        if home is None and foods is None:\n",
    "            continue\n",
    "        \n",
    "        # get homeless information\n",
    "        if home is None:\n",
    "            homeless = -1\n",
    "            homeless_trend = 0\n",
    "        else:\n",
    "            try:\n",
    "                homeless = dic['homeless']['cnt16']\n",
    "                homeless_trend = dic['homeless']['incre/decre']\n",
    "            except:\n",
    "                continue\n",
    "        # get food\n",
    "        if foods is None or len(foods) == 0:\n",
    "            writer.writerow([i, time, timestamp, lat, lng, dic['polarity'], dic['user']['followers'], \\\n",
    "                             dic['user']['following'], homeless, homeless_trend, \"-1\"])\n",
    "            i += 1\n",
    "        else:\n",
    "            for food in foods:\n",
    "                food_class = get_food_class(food)\n",
    "                writer.writerow([i, time, timestamp, lat, lng, dic['polarity'], dic['user']['followers'], \\\n",
    "                             dic['user']['following'], homeless, homeless_trend, food_class])\n",
    "                i += 1\n",
    "    csvfile.close()\n",
    "    \n",
    "def trans_month(month):\n",
    "    month_dic = {'Jan': '01', 'Feb': '02', 'Mar': '03', 'Apr': '04', 'May': '05', 'Jun': '06', \\\n",
    "                 'Jul': '07', 'Aug': '08', 'Sep': '09', 'Oct': '10', 'Nov': '11', 'Dec': '12'}\n",
    "    return month_dic[month]\n",
    "\n",
    "def get_food_class(food):\n",
    "    if not food in food_dict.keys():\n",
    "        food_dict[food] = str(len(food_dict))\n",
    "    return food_dict[food]\n",
    "\n",
    "def generate_rev_dict():\n",
    "    for key,value in food_dict.items():\n",
    "        rev_dict[value] = key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_NAME = \"random forest model\"\n",
    "SPARK_URL = \"local[*]\"\n",
    "RANDOM_SEED = 12345\n",
    "TRAINING_DATA_RATIO = 0.7\n",
    "RF_NUM_TREES = 10\n",
    "RF_MAX_DEPTH = 5\n",
    "RF_NUM_BINS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(APP_NAME) \\\n",
    "    .master(SPARK_URL) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/duer/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:25: DeprecationWarning: generator 'CouchDatabase.__iter__' raised StopIteration\n"
     ]
    }
   ],
   "source": [
    "# read data from couchdb and reform them into a dataframe\n",
    "trans(REFORMED_FILE)\n",
    "\n",
    "df = spark.read \\\n",
    "    .options(header = \"true\", inferschema = \"true\") \\\n",
    "    .csv(REFORMED_FILE)\n",
    "\n",
    "print(\"Total number of rows: %d\" % df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-------------+------------+-----------+--------+---------+---------+--------+--------------+----------+\n",
      "| id|               time|    timestamp|         lat|        lng|polarity|followers|following|homeless|homeless_trend|food_class|\n",
      "+---+-------------------+-------------+------------+-----------+--------+---------+---------+--------+--------------+----------+\n",
      "|  0|26-04-2018 02:19:47|1.524673187E9| -37.7760072|144.9708071|  0.8883|      380|      564|       4|            -9|         0|\n",
      "|  1|26-04-2018 12:44:13|1.524710653E9| -33.8688197|151.2092955|  0.4019|      766|      552|      -1|             0|         0|\n",
      "|  2|26-04-2018 13:15:36|1.524712536E9| -37.8136276|144.9630576|     0.0|      853|      558|      -1|             0|         0|\n",
      "|  3|26-04-2018 13:23:29|1.524713009E9|-33.86642251|151.2012542|     0.0|       37|      169|    5061|          2024|         0|\n",
      "|  4|26-04-2018 09:45:28|1.524699928E9|    -28.0183|   153.3921|   0.926|       84|      143|    1708|           368|         0|\n",
      "|  5|26-04-2018 11:10:58|1.524705058E9| -33.8688197|151.2092955| -0.2484|      154|      219|      -1|             0|         0|\n",
      "|  6|26-04-2018 11:10:58|1.524705058E9| -33.8688197|151.2092955| -0.2484|      154|      219|      -1|             0|         1|\n",
      "|  7|26-04-2018 02:58:37|1.524675517E9|   -33.88888|  151.27759|     0.0|     4111|     4550|     165|            44|         0|\n",
      "|  8|28-04-2018 14:45:30| 1.52489073E9| -37.8136276|144.9630576| -0.3078|       93|      477|      -1|             0|         0|\n",
      "|  9|29-04-2018 04:50:28|1.524941428E9| -33.8688197|151.2092955|  0.7543|      168|      206|      -1|             0|         0|\n",
      "| 10|29-04-2018 05:15:22|1.524942922E9|    -37.8823|      144.7|   0.296|      363|      472|     750|           120|         0|\n",
      "| 11|29-04-2018 05:15:22|1.524942922E9|    -37.8823|      144.7|   0.296|      363|      472|     750|           120|         2|\n",
      "| 12|28-04-2018 22:53:59|1.524920039E9| -37.4713077|144.7851531|  0.8674|      805|      608|      -1|             0|         0|\n",
      "| 13|28-04-2018 22:57:28|1.524920248E9|  -28.016667|      153.4|  0.1999|     1831|     2342|      -1|             0|         0|\n",
      "| 14|29-04-2018 07:49:26|1.524952166E9|  -27.999481|  153.42798|  0.6369|     2617|     1081|    1708|           368|         0|\n",
      "| 15|29-04-2018 03:17:22|1.524935842E9| -37.8136276|144.9630576|  0.8807|      804|      805|      -1|             0|         0|\n",
      "| 16|28-04-2018 10:31:07|1.524875467E9| -33.8688197|151.2092955|  0.4005|      154|      384|      -1|             0|         0|\n",
      "| 17|28-04-2018 10:34:33|1.524875673E9| -38.1353835|145.8487441|  0.3169|      105|      326|      -1|             0|         0|\n",
      "| 18|28-04-2018 10:34:33|1.524875673E9| -38.1353835|145.8487441|  0.3169|      105|      326|      -1|             0|         3|\n",
      "| 19|28-04-2018 10:58:05|1.524877085E9| -36.8875485|149.9058748|  0.7845|      110|      142|      -1|             0|         0|\n",
      "+---+-------------------+-------------+------------+-----------+--------+---------+---------+--------+--------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows having all information: 20\n",
      "number of rows without food information: 0\n",
      "number of rows without homeless information: 26\n"
     ]
    }
   ],
   "source": [
    "# filter dataframe\n",
    "df_no_food = df.filter(df['food_class'] == -1)\n",
    "df_no_homeless = df.filter(df['homeless'] == -1)\n",
    "df_all_info = df.filter(df['food_class'] >= 0).filter(df['homeless'] >= 0)\n",
    "\n",
    "print(\"Number of rows having all information: %d\" % df_all_info.count())\n",
    "print(\"number of rows without food information: %d\" % df_no_food.count())\n",
    "print(\"number of rows without homeless information: %d\" % df_no_homeless.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training set rows: 15\n",
      "Number of test set rows: 5\n"
     ]
    }
   ],
   "source": [
    "# transform dataframe into RDD and split reformed data into tranning data and test data\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "transformed_df_food = df_all_info.rdd.map(lambda row: LabeledPoint(row[-1], Vectors.dense(row[2:-1])))\n",
    "transformed_df_homeless = df_all_info.rdd.map(lambda row: LabeledPoint(row[-3], Vectors.dense(row[2],row[3],row[4],row[5],row[6],row[7],row[10])))\n",
    "transformed_df_homeless_trend = df_all_info.rdd.map(lambda row: LabeledPoint(row[-2], Vectors.dense(row[2],row[3],row[4],row[5],row[6],row[7],row[10])))\n",
    "\n",
    "splits = [TRAINING_DATA_RATIO, 1.0 - TRAINING_DATA_RATIO]\n",
    "training_data_food, test_data_food = transformed_df_food.randomSplit(splits, RANDOM_SEED)\n",
    "training_data_homeless, test_data_homeless = transformed_df_homeless.randomSplit(splits, RANDOM_SEED)\n",
    "training_data_homeless_trend, test_data_homeless_trend = transformed_df_homeless_trend.randomSplit(splits, RANDOM_SEED)\n",
    "\n",
    "print(\"Number of training set rows: %d\" % training_data_food.count())\n",
    "print(\"Number of test set rows: %d\" % test_data_food.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train food classifier: 0.268 seconds\n"
     ]
    }
   ],
   "source": [
    "# train the classification model using training data\n",
    "from pyspark.mllib.tree import RandomForest\n",
    "from time import *\n",
    "\n",
    "start_time = time()\n",
    "num_classes = len(food_dict)\n",
    "\n",
    "model_food_classifier = RandomForest.trainClassifier(training_data_food, numClasses=num_classes, categoricalFeaturesInfo={}, \\\n",
    "    numTrees=RF_NUM_TREES, featureSubsetStrategy=\"auto\", impurity=\"gini\", \\\n",
    "    maxDepth=RF_MAX_DEPTH, maxBins=32, seed=RANDOM_SEED)\n",
    "\n",
    "end_time = time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Time to train food classifier: %.3f seconds\" % elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train homeless regressor: 0.524 seconds\n"
     ]
    }
   ],
   "source": [
    "# train the regression model using training data\n",
    "start_time = time()\n",
    "\n",
    "model_homeless_regressor = RandomForest.trainRegressor(training_data_homeless, categoricalFeaturesInfo={}, \\\n",
    "    numTrees=RF_NUM_TREES, featureSubsetStrategy=\"auto\", impurity=\"variance\", \\\n",
    "    maxDepth=RF_MAX_DEPTH, maxBins=32, seed=RANDOM_SEED)\n",
    "\n",
    "model_homeless_trend_regressor = RandomForest.trainRegressor(training_data_homeless_trend, categoricalFeaturesInfo={}, \\\n",
    "    numTrees=RF_NUM_TREES, featureSubsetStrategy=\"auto\", impurity=\"variance\", \\\n",
    "    maxDepth=RF_MAX_DEPTH, maxBins=32, seed=RANDOM_SEED)\n",
    "\n",
    "end_time = time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Time to train homeless regressor: %.3f seconds\" % elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Food classifier accuracy: 80.000%\n",
      "Homeless regressor accuracy: 0.000%\n",
      "Homeless trend regressor accuracy: 40.000%\n"
     ]
    }
   ],
   "source": [
    "# make predictions using test data and calculate the accuracy\n",
    "food_predictions = model_food_classifier.predict(test_data_food.map(lambda x: x.features))\n",
    "homeless_predictions = model_homeless_regressor.predict(test_data_homeless.map(lambda x: x.features))\n",
    "homeless_trend_predictions = model_homeless_trend_regressor.predict(test_data_homeless_trend.map(lambda x: x.features))\n",
    "\n",
    "\n",
    "labels_and_predictions_food = test_data_food.map(lambda x: x.label).zip(food_predictions)\n",
    "labels_and_predictions_homeless = test_data_homeless.map(lambda x: x.label).zip(homeless_predictions)\n",
    "labels_and_predictions_homeless_trend = test_data_homeless_trend.map(lambda x: x.label).zip(homeless_trend_predictions)\n",
    "\n",
    "food_acc = labels_and_predictions_food.filter(lambda x: x[0] == x[1]).count() / float(test_data_food.count())\n",
    "homeless_acc = labels_and_predictions_homeless.filter(lambda x: abs(x[0]-x[1]) < 100).count() / float(test_data_homeless.count())\n",
    "homeless_trend_acc = labels_and_predictions_homeless_trend.filter(lambda x: abs(x[0]-x[1]) < 100).count() / float(test_data_homeless_trend.count())\n",
    "\n",
    "print(\"Food classifier accuracy: %.3f%%\" % (food_acc * 100))\n",
    "print(\"Homeless regressor accuracy: %.3f%%\" % (homeless_acc * 100))\n",
    "print(\"Homeless trend regressor accuracy: %.3f%%\" % (homeless_trend_acc * 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_pre = df_no_food.count() > 0\n",
    "homeless_pre = df_no_homeless.count() > 0\n",
    "\n",
    "# make food predictions\n",
    "if food_pre:\n",
    "    transformed_df_no_food = df_no_food.rdd.map(lambda row: LabeledPoint(row[-1], Vectors.dense(row[2:-1])))\n",
    "    predict_foods = model_food_classifier.predict(transformed_df_no_food.map(lambda x: x.features))\n",
    "\n",
    "# make homeless predictions\n",
    "if homeless_pre:\n",
    "    transformed_df_no_homeless = df_no_homeless.rdd.map(lambda row: LabeledPoint(row[8], Vectors.dense(row[2],row[3],row[4],row[5],row[6],row[7],row[10])))\n",
    "    transformed_df_no_homeless_trend = df_no_homeless.rdd.map(lambda row: LabeledPoint(row[9], Vectors.dense(row[2],row[3],row[4],row[5],row[6],row[7],row[10])))\n",
    "    predict_homeless = model_homeless_regressor.predict(transformed_df_no_homeless.map(lambda x: x.features))\n",
    "    predict_homeless_trend = model_homeless_trend_regressor.predict(transformed_df_no_homeless_trend.map(lambda x: x.features))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine id with predictions\n",
    "if food_pre:\n",
    "    rdd_predict_foods = df_no_food.rdd.map(lambda row: row[0]).zip(predict_foods.map(int))\n",
    "    list_predict_foods = rdd_predict_foods.collect()\n",
    "if homeless_pre:\n",
    "    rdd_predict_homeless = df_no_homeless.rdd.map(lambda row: row[0]).zip(predict_homeless.map(int))\n",
    "    rdd_predict_homeless_trend = df_no_homeless.rdd.map(lambda row: row[0]).zip(predict_homeless_trend.map(int))\n",
    "    list_predict_homeless = rdd_predict_homeless.collect()\n",
    "    list_predict_homeless_trend = rdd_predict_homeless_trend.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform predicted rdd to dataframe and join it to original data that without food\n",
    "if food_pre:\n",
    "    df_predict_foods = spark.createDataFrame(list_predict_foods, schema=[\"id\",\"food_class\"])\n",
    "    df_no_food = df_no_food.drop('food_class')\n",
    "    concat_df_food = df_no_food.join(df_predict_foods, on='id')\n",
    "    \n",
    "if homeless_pre:\n",
    "    df_predict_homeless = spark.createDataFrame(list_predict_homeless, schema=[\"id\",\"homeless\"])\n",
    "    df_predict_homeless_trend = spark.createDataFrame(list_predict_homeless_trend, schema=[\"id\",\"homeless_trend\"])\n",
    "    \n",
    "    df_no_homeless = df_no_homeless.drop('homeless').drop('homeless_trend')\n",
    "    concat_df_homeless = df_no_homeless.join(df_predict_homeless, on='id').join(df_predict_homeless_trend, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-------------+-----------+-----------+--------+---------+---------+----------+--------+--------------+\n",
      "| id|               time|    timestamp|        lat|        lng|polarity|followers|following|food_class|homeless|homeless_trend|\n",
      "+---+-------------------+-------------+-----------+-----------+--------+---------+---------+----------+--------+--------------+\n",
      "| 26|29-04-2018 06:25:24|1.524947124E9|-38.3686779|142.4982086|     0.0|      775|      745|         0|    1568|            52|\n",
      "| 19|28-04-2018 10:58:05|1.524877085E9|-36.8875485|149.9058748|  0.7845|      110|      142|         0|    1215|           378|\n",
      "| 43|26-04-2018 04:24:41|1.524680681E9|-37.8136276|144.9630576|     0.0|      142|       68|         0|    2468|           769|\n",
      "| 39|26-04-2018 07:32:15|1.524691935E9|-27.4697707|153.0251235|     0.0|      716|      625|         0|    1717|           299|\n",
      "|  6|26-04-2018 11:10:58|1.524705058E9|-33.8688197|151.2092955| -0.2484|      154|      219|         1|    2145|          1248|\n",
      "|  6|26-04-2018 11:10:58|1.524705058E9|-33.8688197|151.2092955| -0.2484|      154|      219|         1|    2145|          1248|\n",
      "|  9|29-04-2018 04:50:28|1.524941428E9|-33.8688197|151.2092955|  0.7543|      168|      206|         0|    1908|          -335|\n",
      "| 27|29-04-2018 06:35:37|1.524947737E9|-37.8136276|144.9630576| -0.4466|      331|      566|         3|     439|            13|\n",
      "| 27|29-04-2018 06:35:37|1.524947737E9|-37.8136276|144.9630576| -0.4466|      331|      566|         3|     425|            13|\n",
      "| 17|28-04-2018 10:34:33|1.524875673E9|-38.1353835|145.8487441|  0.3169|      105|      326|         0|     732|          -437|\n",
      "| 44|26-04-2018 04:25:24|1.524680724E9|-34.9284989|138.6007456|  0.6486|      903|      374|         0|    3402|           893|\n",
      "| 37|28-04-2018 14:08:11|1.524888491E9|-31.0604769|152.8481977| -0.4898|      585|      433|         0|    1032|           117|\n",
      "| 12|28-04-2018 22:53:59|1.524920039E9|-37.4713077|144.7851531|  0.8674|      805|      608|         0|     888|          1142|\n",
      "| 12|28-04-2018 22:53:59|1.524920039E9|-37.4713077|144.7851531|  0.8674|      805|      608|         0|     888|            74|\n",
      "|  2|26-04-2018 13:15:36|1.524712536E9|-37.8136276|144.9630576|     0.0|      853|      558|         0|     706|           520|\n",
      "|  2|26-04-2018 13:15:36|1.524712536E9|-37.8136276|144.9630576|     0.0|      853|      558|         0|     706|            34|\n",
      "| 36|28-04-2018 13:44:36|1.524887076E9|-41.4545196|145.9706647|  0.4939|        8|       18|         0|    2831|          1191|\n",
      "| 18|28-04-2018 10:34:33|1.524875673E9|-38.1353835|145.8487441|  0.3169|      105|      326|         3|     732|          -450|\n",
      "| 21|28-04-2018 11:04:38|1.524877478E9|-31.9505269|115.8604572|  0.4215|     1919|      288|         3|    1604|           956|\n",
      "| 15|29-04-2018 03:17:22|1.524935842E9|-37.8136276|144.9630576|  0.8807|      804|      805|         0|     895|            61|\n",
      "+---+-------------------+-------------+-----------+-----------+--------+---------+---------+----------+--------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "concat_df_homeless.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-------------+------------+------------+--------+---------+---------+--------+--------------+----------+\n",
      "| id|               time|    timestamp|         lat|         lng|polarity|followers|following|homeless|homeless_trend|food_class|\n",
      "+---+-------------------+-------------+------------+------------+--------+---------+---------+--------+--------------+----------+\n",
      "|  0|26-04-2018 02:19:47|1.524673187E9| -37.7760072| 144.9708071|  0.8883|      380|      564|       4|            -9|         0|\n",
      "|  3|26-04-2018 13:23:29|1.524713009E9|-33.86642251| 151.2012542|     0.0|       37|      169|    5061|          2024|         0|\n",
      "|  4|26-04-2018 09:45:28|1.524699928E9|    -28.0183|    153.3921|   0.926|       84|      143|    1708|           368|         0|\n",
      "|  7|26-04-2018 02:58:37|1.524675517E9|   -33.88888|   151.27759|     0.0|     4111|     4550|     165|            44|         0|\n",
      "| 10|29-04-2018 05:15:22|1.524942922E9|    -37.8823|       144.7|   0.296|      363|      472|     750|           120|         0|\n",
      "| 11|29-04-2018 05:15:22|1.524942922E9|    -37.8823|       144.7|   0.296|      363|      472|     750|           120|         2|\n",
      "| 14|29-04-2018 07:49:26|1.524952166E9|  -27.999481|   153.42798|  0.6369|     2617|     1081|    1708|           368|         0|\n",
      "| 22|28-04-2018 12:01:27|1.524880887E9|   -33.23436| 151.5560099|     0.0|      155|     1010|      13|            10|         0|\n",
      "| 25|28-04-2018 08:46:31|1.524869191E9|-38.14565147|145.25486876|     0.0|      457|     1076|       4|            -9|         0|\n",
      "| 28|29-04-2018 06:51:22|1.524948682E9|      -36.75|     146.317|     0.0|     1103|     1633|      75|           -30|         0|\n",
      "| 29|29-04-2018 07:00:00|  1.5249492E9|   -33.89607|   150.91241|     0.0|      396|     1082|    1058|           280|         0|\n",
      "| 30|29-04-2018 07:15:59|1.524950159E9|    -28.0183|    153.3921|  0.6369|      672|     1477|    1708|           368|         0|\n",
      "| 31|29-04-2018 07:15:59|1.524950159E9|    -28.0183|    153.3921|  0.6369|      672|     1477|    1708|           368|         2|\n",
      "| 32|28-04-2018 06:22:55|1.524860575E9|  -37.816127| 145.1942314|     0.0|      782|      577|       4|            -9|         0|\n",
      "| 33|28-04-2018 06:39:08|1.524861548E9|   -27.67859|   153.02245|     0.0|      179|      349|    1205|           179|         0|\n",
      "| 34|28-04-2018 07:00:24|1.524862824E9|-33.88720186|151.17431956| -0.6688|       84|      618|       0|         -1215|         0|\n",
      "| 35|28-04-2018 07:34:31|1.524864871E9|-33.77347581|150.97147078|   -0.34|      174|      299|     987|           987|         0|\n",
      "| 40|26-04-2018 07:32:35|1.524691955E9|   -37.81191|   144.97188|  0.3612|      302|      479|       4|            -9|         0|\n",
      "| 41|26-04-2018 07:32:35|1.524691955E9|   -37.81191|   144.97188|  0.3612|      302|      479|       4|            -9|         4|\n",
      "| 45|26-04-2018 05:12:19|1.524683539E9| -33.8583283|151.20948426|  0.6369|     1650|      920|    5061|          2024|         0|\n",
      "+---+-------------------+-------------+------------+------------+--------+---------+---------+--------+--------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_all_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "+-------------------+------------+------------+--------+---------+---------+--------+--------------+-------+----------+\n",
      "|               time|         lat|         lng|polarity|followers|following|homeless|homeless_trend|   food|food_group|\n",
      "+-------------------+------------+------------+--------+---------+---------+--------+--------------+-------+----------+\n",
      "|26-04-2018 02:19:47| -37.7760072| 144.9708071|  0.8883|      380|      564|       4|            -9|  pizza|  fastfood|\n",
      "|26-04-2018 13:23:29|-33.86642251| 151.2012542|     0.0|       37|      169|    5061|          2024|  pizza|  fastfood|\n",
      "|26-04-2018 09:45:28|    -28.0183|    153.3921|   0.926|       84|      143|    1708|           368|  pizza|  fastfood|\n",
      "|26-04-2018 02:58:37|   -33.88888|   151.27759|     0.0|     4111|     4550|     165|            44|  pizza|  fastfood|\n",
      "|29-04-2018 05:15:22|    -37.8823|       144.7|   0.296|      363|      472|     750|           120|  pizza|  fastfood|\n",
      "|29-04-2018 05:15:22|    -37.8823|       144.7|   0.296|      363|      472|     750|           120|chicken|      meat|\n",
      "|29-04-2018 07:49:26|  -27.999481|   153.42798|  0.6369|     2617|     1081|    1708|           368|  pizza|  fastfood|\n",
      "|28-04-2018 12:01:27|   -33.23436| 151.5560099|     0.0|      155|     1010|      13|            10|  pizza|  fastfood|\n",
      "|28-04-2018 08:46:31|-38.14565147|145.25486876|     0.0|      457|     1076|       4|            -9|  pizza|  fastfood|\n",
      "|29-04-2018 06:51:22|      -36.75|     146.317|     0.0|     1103|     1633|      75|           -30|  pizza|  fastfood|\n",
      "|29-04-2018 07:00:00|   -33.89607|   150.91241|     0.0|      396|     1082|    1058|           280|  pizza|  fastfood|\n",
      "|29-04-2018 07:15:59|    -28.0183|    153.3921|  0.6369|      672|     1477|    1708|           368|  pizza|  fastfood|\n",
      "|29-04-2018 07:15:59|    -28.0183|    153.3921|  0.6369|      672|     1477|    1708|           368|chicken|      meat|\n",
      "|28-04-2018 06:22:55|  -37.816127| 145.1942314|     0.0|      782|      577|       4|            -9|  pizza|  fastfood|\n",
      "|28-04-2018 06:39:08|   -27.67859|   153.02245|     0.0|      179|      349|    1205|           179|  pizza|  fastfood|\n",
      "|28-04-2018 07:00:24|-33.88720186|151.17431956| -0.6688|       84|      618|       0|         -1215|  pizza|  fastfood|\n",
      "|28-04-2018 07:34:31|-33.77347581|150.97147078|   -0.34|      174|      299|     987|           987|  pizza|  fastfood|\n",
      "|26-04-2018 07:32:35|   -37.81191|   144.97188|  0.3612|      302|      479|       4|            -9|  pizza|  fastfood|\n",
      "|26-04-2018 07:32:35|   -37.81191|   144.97188|  0.3612|      302|      479|       4|            -9| potato|vegetables|\n",
      "|26-04-2018 05:12:19| -33.8583283|151.20948426|  0.6369|     1650|      920|    5061|          2024|  pizza|  fastfood|\n",
      "+-------------------+------------+------------+--------+---------+---------+--------+--------------+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get food type according to food class\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "from keywords import Keywords\n",
    "\n",
    "generate_rev_dict()\n",
    "    \n",
    "# get food name by food class\n",
    "def get_food_type(food_class):\n",
    "    the_class = str(food_class)\n",
    "    if the_class in rev_dict.keys():\n",
    "        return rev_dict[the_class]\n",
    "    return None\n",
    "get_food_type_udf = udf(get_food_type, StringType())\n",
    "\n",
    "# get food group by food name\n",
    "def get_food_group(food):\n",
    "        if food in Keywords.fastfood:\n",
    "            return \"fastfood\"\n",
    "        if food in Keywords.fruits:\n",
    "            return \"fruits\"\n",
    "        if food in Keywords.grains:\n",
    "            return \"grains\"\n",
    "        if food in Keywords.meat:\n",
    "            return \"meat\"\n",
    "        if food in Keywords.seafood:\n",
    "            return \"seafood\"\n",
    "        if food in Keywords.vegetables:\n",
    "            return \"vegetables\"\n",
    "        return None\n",
    "get_food_group_udf = udf(get_food_group, StringType())\n",
    "\n",
    "df_all_info = df_all_info.withColumn('food', get_food_type_udf(df_all_info['food_class']))\n",
    "df_all_info = df_all_info.drop('food_class')\n",
    "\n",
    "# reform the dataframe to prepare for tranforming to json\n",
    "if food_pre:\n",
    "    concat_df_food = concat_df_food.withColumn('food', get_food_type_udf(concat_df_food['food_class']))\n",
    "    concat_df_food = concat_df_food.drop('food_class')\n",
    "\n",
    "    unioin_df = df_all_info.union(concat_df_food)\n",
    "else:\n",
    "    unioin_df = df_all_info\n",
    "    \n",
    "    \n",
    "if homeless_pre:\n",
    "    concat_df_homeless = concat_df_homeless.withColumn('food', get_food_type_udf(concat_df_homeless['food_class']))\n",
    "    concat_df_homeless = concat_df_homeless.drop('food_class')\n",
    "    \n",
    "    unioin_df = unioin_df.union(concat_df_homeless)\n",
    "\n",
    "    \n",
    "unioin_df = unioin_df.drop('id')\n",
    "unioin_df = unioin_df.drop('timestamp')\n",
    "\n",
    "unioin_df = unioin_df.withColumn('food_group', get_food_group_udf(unioin_df['food']))\n",
    "\n",
    "print(unioin_df.count())\n",
    "unioin_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = unioin_df.toJSON()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"time\":\"26-04-2018 02:19:47\",\"lat\":-37.7760072,\"lng\":144.9708071,\"polarity\":0.8883,\"followers\":380,\"following\":564,\"homeless\":4,\"homeless_trend\":-9,\"food\":\"pizza\",\"food_group\":\"fastfood\"}'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert success\n"
     ]
    }
   ],
   "source": [
    "# insert data into couchdb\n",
    "my_db = Couch('test002')\n",
    "\n",
    "final_json = {}\n",
    "final_json[\"type\"] = \"FeatureCollection\"\n",
    "final_json[\"features\"] = []\n",
    "\n",
    "#i = 0\n",
    "for row in json_data.collect():\n",
    "    #print(i)\n",
    "    entry = {}\n",
    "    entry[\"type\"] = \"Feature\"\n",
    "    entry[\"properties\"] = {}\n",
    "    entry[\"geometry\"] = {}\n",
    "    entry[\"geometry\"][\"type\"] = \"Point\"\n",
    "    entry[\"geometry\"][\"coordinates\"] = []\n",
    "    \n",
    "    json_obj = json.loads(row)\n",
    "    entry[\"properties\"][\"time\"] = json_obj[\"time\"]\n",
    "    entry[\"properties\"][\"polarity\"] = json_obj[\"polarity\"]\n",
    "    entry[\"properties\"][\"followers\"] = json_obj[\"followers\"]\n",
    "    entry[\"properties\"][\"following\"] = json_obj[\"following\"]\n",
    "    entry[\"properties\"][\"food\"] = json_obj[\"food\"]\n",
    "    entry[\"properties\"][\"food_group\"] = json_obj[\"food_group\"]\n",
    "    entry[\"properties\"][\"homeless\"] = json_obj[\"homeless\"]\n",
    "    entry[\"properties\"][\"homeless_trend\"] = json_obj[\"homeless_trend\"]\n",
    "    entry[\"geometry\"][\"coordinates\"].append(json_obj[\"lat\"])\n",
    "    entry[\"geometry\"][\"coordinates\"].append(json_obj[\"lng\"])\n",
    "    \n",
    "    final_json[\"features\"].append(entry)\n",
    "    #i += 1\n",
    "my_db.insert(final_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
