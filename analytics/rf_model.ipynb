{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ['SPARK_HOME'] = \"spark\"\n",
    "sys.path.append(\"spark/python\")\n",
    "sys.path.append(\"spark/python/lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get coordinates of a given city\n",
    "import httplib2\n",
    "import json\n",
    "\n",
    "\n",
    "def cityPos(name):\n",
    "    url = \"https://maps.googleapis.com/maps/api/geocode/json?\" + \\\n",
    "          \"key=AIzaSyBsZErhxaT1oVgMrT-xGLcAN5nK3UHeGBU&address=\" + name\n",
    "    req = httplib2.Http(\".cache\")\n",
    "    resp, content = req.request(url, \"GET\")\n",
    "    res = json.loads(content)\n",
    "    return res[\"results\"][0][\"geometry\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reform the data preparing for fitting the model\n",
    "import csv\n",
    "import json\n",
    "import codecs\n",
    "import time as t\n",
    "from couch import Couch\n",
    "\n",
    "COUCHDB_NAME = \"cl_richard\"\n",
    "#COUCHDB_NAME = \"classified1\"\n",
    "REFORMED_FILE = \"data/output0.csv\"\n",
    "\n",
    "food_dict = {}\n",
    "rev_dict = {}\n",
    "\n",
    "def trans(path):\n",
    "    con = Couch(COUCHDB_NAME)\n",
    "    jsonData = con.query_all()\n",
    "\n",
    "    csvfile = open(REFORMED_FILE, 'w', newline='')\n",
    "    writer = csv.writer(csvfile, delimiter=',', quoting=csv.QUOTE_ALL)\n",
    "    keys=['id', 'time', 'timestamp', 'lat', 'lng', 'polarity', 'followers', 'following', 'homeless', \\\n",
    "          'homeless_trend', 'food_class']\n",
    "    writer.writerow(keys)\n",
    "    \n",
    "    i = 0\n",
    "    for dic in jsonData:\n",
    "        # get coordinates\n",
    "        if dic['location']['coordinates'] is None:\n",
    "            city = dic['location']['place_name']\n",
    "            city = city.replace(\" \",\"%20\")\n",
    "            coor = cityPos(city)\n",
    "            lng = coor['location']['lng']\n",
    "            lat = coor['location']['lat']\n",
    "        else:\n",
    "            lng = dic['location']['coordinates'][0]\n",
    "            lat = dic['location']['coordinates'][1]\n",
    "            \n",
    "        # get time amd timesptamp\n",
    "        time = dic['created_at']['day']+'-'+trans_month(dic['created_at']['month'])+'-'+dic['created_at']['year']+\\\n",
    "                ' '+dic['created_at']['time']\n",
    "        timeArray = t.strptime(time, \"%d-%m-%Y %H:%M:%S\")\n",
    "        timestamp = t.mktime(timeArray)\n",
    "        \n",
    "        # to ensure at least one of homeless info and food info appears\n",
    "        home = dic['homeless']\n",
    "        foods = dic['food_list']\n",
    "        if home is None and foods is None:\n",
    "            continue\n",
    "        \n",
    "        # get homeless information\n",
    "        if home is None:\n",
    "            homeless = -1\n",
    "            homeless_trend = 0\n",
    "        else:\n",
    "            try:\n",
    "                homeless = dic['homeless']['cnt16']\n",
    "                homeless_trend = dic['homeless']['incre/decre']\n",
    "            except:\n",
    "                continue\n",
    "        # get food\n",
    "        if foods is None or len(foods) == 0:\n",
    "            writer.writerow([i, time, timestamp, lat, lng, dic['polarity'], dic['user']['followers'], \\\n",
    "                             dic['user']['following'], homeless, homeless_trend, \"-1\"])\n",
    "            i += 1\n",
    "        else:\n",
    "            for food in foods:\n",
    "                food_class = get_food_class(food)\n",
    "                writer.writerow([i, time, timestamp, lat, lng, dic['polarity'], dic['user']['followers'], \\\n",
    "                             dic['user']['following'], homeless, homeless_trend, food_class])\n",
    "                i += 1\n",
    "    csvfile.close()\n",
    "    \n",
    "def trans_month(month):\n",
    "    month_dic = {'Jan': '01', 'Feb': '02', 'Mar': '03', 'Apr': '04', 'May': '05', 'Jun': '06', \\\n",
    "                 'Jul': '07', 'Aug': '08', 'Sep': '09', 'Oct': '10', 'Nov': '11', 'Dec': '12'}\n",
    "    return month_dic[month]\n",
    "\n",
    "def get_food_class(food):\n",
    "    if not food in food_dict.keys():\n",
    "        food_dict[food] = str(len(food_dict))\n",
    "    return food_dict[food]\n",
    "\n",
    "def generate_rev_dict():\n",
    "    for key,value in food_dict.items():\n",
    "        rev_dict[value] = key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_NAME = \"random forest model\"\n",
    "SPARK_URL = \"local[*]\"\n",
    "RANDOM_SEED = 12345\n",
    "TRAINING_DATA_RATIO = 0.7\n",
    "RF_NUM_TREES = 10\n",
    "RF_MAX_DEPTH = 5\n",
    "RF_NUM_BINS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(APP_NAME) \\\n",
    "    .master(SPARK_URL) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/duer/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:25: DeprecationWarning: generator 'CouchDatabase.__iter__' raised StopIteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 11885\n"
     ]
    }
   ],
   "source": [
    "# read data from couchdb and reform them into a dataframe\n",
    "trans(REFORMED_FILE)\n",
    "\n",
    "df = spark.read \\\n",
    "    .options(header = \"true\", inferschema = \"true\") \\\n",
    "    .csv(REFORMED_FILE)\n",
    "\n",
    "print(\"Total number of rows: %d\" % df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-------------+------------+------------+--------+---------+---------+--------+--------------+----------+\n",
      "| id|               time|    timestamp|         lat|         lng|polarity|followers|following|homeless|homeless_trend|food_class|\n",
      "+---+-------------------+-------------+------------+------------+--------+---------+---------+--------+--------------+----------+\n",
      "|  0|21-12-2015 04:19:48|1.450631988E9|-37.82388645|145.06862749|     0.0|      136|      110|       4|            -9|         0|\n",
      "|  1|21-12-2015 08:43:20|  1.4506478E9|-37.81337025|144.96843006|     0.0|     2154|     2078|       4|            -9|         1|\n",
      "|  2|21-12-2015 08:43:20|  1.4506478E9|-37.81337025|144.96843006|     0.0|     2154|     2078|       4|            -9|         2|\n",
      "|  3|21-12-2015 08:43:20|  1.4506478E9|-37.81337025|144.96843006|     0.0|     2154|     2078|       4|            -9|         3|\n",
      "|  4|21-12-2015 08:43:20|  1.4506478E9|-37.81337025|144.96843006|     0.0|     2154|     2078|       4|            -9|         4|\n",
      "|  5|21-12-2015 11:17:03|1.450657023E9| -37.8187599| 144.9556732|  0.6249|       50|       48|       4|            -9|         4|\n",
      "|  6|21-12-2015 12:58:03|1.450663083E9|-37.76600978|144.98401132|  -0.296|     1346|     1023|       4|            -9|         5|\n",
      "|  7|21-12-2015 18:58:11|1.450684691E9|   -37.86511|   145.10127|  -0.296|      273|        1|       4|            -9|         6|\n",
      "|  8|22-12-2015 00:48:32|1.450705712E9|-37.81124367|144.96010321|  0.4588|      499|      254|       4|            -9|         7|\n",
      "|  9|22-12-2015 01:50:44|1.450709444E9| -37.8332176|  145.047348|  0.4404|      587|      631|       4|            -9|         8|\n",
      "| 10|22-12-2015 01:50:44|1.450709444E9| -37.8332176|  145.047348|  0.4404|      587|      631|       4|            -9|         9|\n",
      "| 11|22-12-2015 02:54:37|1.450713277E9|    -37.7998|     144.994|   0.126|      920|     2077|       4|            -9|         1|\n",
      "| 12|22-12-2015 03:28:25|1.450715305E9|-37.84016906|144.99552313|     0.0|      317|      472|       4|            -9|        10|\n",
      "| 13|22-12-2015 03:28:25|1.450715305E9|-37.84016906|144.99552313|     0.0|      317|      472|       4|            -9|        11|\n",
      "| 14|22-12-2015 03:43:31|1.450716211E9| -37.8558592|145.36530693|     0.0|      376|      506|       4|            -9|        12|\n",
      "| 15|22-12-2015 04:10:46|1.450717846E9| -37.8026085| 144.9475098|  0.6369|      629|      182|       4|            -9|        13|\n",
      "| 16|22-12-2015 04:10:46|1.450717846E9| -37.8026085| 144.9475098|  0.6369|      629|      182|       4|            -9|        14|\n",
      "| 17|22-12-2015 04:10:46|1.450717846E9| -37.8026085| 144.9475098|  0.6369|      629|      182|       4|            -9|        15|\n",
      "| 18|22-12-2015 04:10:46|1.450717846E9| -37.8026085| 144.9475098|  0.6369|      629|      182|       4|            -9|        14|\n",
      "| 19|22-12-2015 06:35:03|1.450726503E9| -37.8171692| 144.9649353|  0.5742|     1109|     1140|       4|            -9|        16|\n",
      "+---+-------------------+-------------+------------+------------+--------+---------+---------+--------+--------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows having all information: 11875\n",
      "number of rows without food information: 10\n",
      "number of rows without homeless information: 0\n"
     ]
    }
   ],
   "source": [
    "# filter dataframe\n",
    "df_no_food = df.filter(df['food_class'] == -1)\n",
    "df_no_homeless = df.filter(df['homeless'] == -1)\n",
    "df_all_info = df.filter(df['food_class'] >= 0).filter(df['homeless'] >= 0)\n",
    "\n",
    "print(\"Number of rows having all information: %d\" % df_all_info.count())\n",
    "print(\"number of rows without food information: %d\" % df_no_food.count())\n",
    "print(\"number of rows without homeless information: %d\" % df_no_homeless.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training set rows: 8215\n",
      "Number of test set rows: 3660\n"
     ]
    }
   ],
   "source": [
    "# transform dataframe into RDD and split reformed data into tranning data and test data\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "transformed_df_food = df_all_info.rdd.map(lambda row: LabeledPoint(row[-1], Vectors.dense(row[2:-1])))\n",
    "transformed_df_homeless = df_all_info.rdd.map(lambda row: LabeledPoint(row[-3], Vectors.dense(row[2],row[3],row[4],row[5],row[6],row[7],row[10])))\n",
    "transformed_df_homeless_trend = df_all_info.rdd.map(lambda row: LabeledPoint(row[-2], Vectors.dense(row[2],row[3],row[4],row[5],row[6],row[7],row[10])))\n",
    "\n",
    "splits = [TRAINING_DATA_RATIO, 1.0 - TRAINING_DATA_RATIO]\n",
    "training_data_food, test_data_food = transformed_df_food.randomSplit(splits, RANDOM_SEED)\n",
    "training_data_homeless, test_data_homeless = transformed_df_homeless.randomSplit(splits, RANDOM_SEED)\n",
    "training_data_homeless_trend, test_data_homeless_trend = transformed_df_homeless_trend.randomSplit(splits, RANDOM_SEED)\n",
    "\n",
    "print(\"Number of training set rows: %d\" % training_data_food.count())\n",
    "print(\"Number of test set rows: %d\" % test_data_food.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train food classifier: 2.004 seconds\n"
     ]
    }
   ],
   "source": [
    "# train the classification model using training data\n",
    "from pyspark.mllib.tree import RandomForest\n",
    "from time import *\n",
    "\n",
    "start_time = time()\n",
    "num_classes = len(food_dict)\n",
    "\n",
    "model_food_classifier = RandomForest.trainClassifier(training_data_food, numClasses=num_classes, categoricalFeaturesInfo={}, \\\n",
    "    numTrees=RF_NUM_TREES, featureSubsetStrategy=\"auto\", impurity=\"gini\", \\\n",
    "    maxDepth=RF_MAX_DEPTH, maxBins=32, seed=RANDOM_SEED)\n",
    "\n",
    "end_time = time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Time to train food classifier: %.3f seconds\" % elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train homeless regressor: 1.454 seconds\n"
     ]
    }
   ],
   "source": [
    "# train the regression model using training data\n",
    "start_time = time()\n",
    "\n",
    "model_homeless_regressor = RandomForest.trainRegressor(training_data_homeless, categoricalFeaturesInfo={}, \\\n",
    "    numTrees=RF_NUM_TREES, featureSubsetStrategy=\"auto\", impurity=\"variance\", \\\n",
    "    maxDepth=RF_MAX_DEPTH, maxBins=32, seed=RANDOM_SEED)\n",
    "\n",
    "model_homeless_trend_regressor = RandomForest.trainRegressor(training_data_homeless_trend, categoricalFeaturesInfo={}, \\\n",
    "    numTrees=RF_NUM_TREES, featureSubsetStrategy=\"auto\", impurity=\"variance\", \\\n",
    "    maxDepth=RF_MAX_DEPTH, maxBins=32, seed=RANDOM_SEED)\n",
    "\n",
    "end_time = time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Time to train homeless regressor: %.3f seconds\" % elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Food classifier accuracy: 12.322%\n",
      "Homeless regressor accuracy: 82.842%\n",
      "Homeless trend regressor accuracy: 98.115%\n"
     ]
    }
   ],
   "source": [
    "# make predictions using test data and calculate the accuracy\n",
    "food_predictions = model_food_classifier.predict(test_data_food.map(lambda x: x.features))\n",
    "homeless_predictions = model_homeless_regressor.predict(test_data_homeless.map(lambda x: x.features))\n",
    "homeless_trend_predictions = model_homeless_trend_regressor.predict(test_data_homeless_trend.map(lambda x: x.features))\n",
    "\n",
    "\n",
    "labels_and_predictions_food = test_data_food.map(lambda x: x.label).zip(food_predictions)\n",
    "labels_and_predictions_homeless = test_data_homeless.map(lambda x: x.label).zip(homeless_predictions)\n",
    "labels_and_predictions_homeless_trend = test_data_homeless_trend.map(lambda x: x.label).zip(homeless_trend_predictions)\n",
    "\n",
    "food_acc = labels_and_predictions_food.filter(lambda x: x[0] == x[1]).count() / float(test_data_food.count())\n",
    "homeless_acc = labels_and_predictions_homeless.filter(lambda x: abs(x[0]-x[1]) < 100).count() / float(test_data_homeless.count())\n",
    "homeless_trend_acc = labels_and_predictions_homeless_trend.filter(lambda x: abs(x[0]-x[1]) < 100).count() / float(test_data_homeless_trend.count())\n",
    "\n",
    "print(\"Food classifier accuracy: %.3f%%\" % (food_acc * 100))\n",
    "print(\"Homeless regressor accuracy: %.3f%%\" % (homeless_acc * 100))\n",
    "print(\"Homeless trend regressor accuracy: %.3f%%\" % (homeless_trend_acc * 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under Precision/Recall (PR) curve: 100\n",
      "Area under Receiver Operating Characteristic (ROC) curve: 100.000\n",
      "Time to evaluate model: 0.284 seconds\n"
     ]
    }
   ],
   "source": [
    "# evaluation that I have no idea what it is\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "metrics = BinaryClassificationMetrics(labels_and_predictions_food)\n",
    "print(\"Area under Precision/Recall (PR) curve: %.f\" % (metrics.areaUnderPR * 100))\n",
    "print(\"Area under Receiver Operating Characteristic (ROC) curve: %.3f\" % (metrics.areaUnderROC * 100))\n",
    "\n",
    "end_time = time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Time to evaluate model: %.3f seconds\" % elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_pre = df_no_food.count() > 0\n",
    "homeless_pre = df_no_homeless.count() > 0\n",
    "\n",
    "# make food predictions\n",
    "if food_pre:\n",
    "    transformed_df_no_food = df_no_food.rdd.map(lambda row: LabeledPoint(row[-1], Vectors.dense(row[2:-1])))\n",
    "    predict_foods = model_food_classifier.predict(transformed_df_no_food.map(lambda x: x.features))\n",
    "\n",
    "# make homeless predictions\n",
    "if homeless_pre:\n",
    "    transformed_df_no_homeless = df_no_homeless.rdd.map(lambda row: LabeledPoint(row[8], Vectors.dense(row[2],row[3],row[4],row[5],row[6],row[7],row[10])))\n",
    "    transformed_df_no_homeless_trend = df_no_homeless.rdd.map(lambda row: LabeledPoint(row[9], Vectors.dense(row[2],row[3],row[4],row[5],row[6],row[7],row[10])))\n",
    "    predict_homeless = model_homeless_regressor.predict(transformed_df_no_homeless.map(lambda x: x.features))\n",
    "    predict_homeless_trend = model_homeless_trend_regressor.predict(transformed_df_no_homeless_trend.map(lambda x: x.features))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine id with predictions\n",
    "if food_pre:\n",
    "    rdd_predict_foods = df_no_food.rdd.map(lambda row: row[0]).zip(predict_foods.map(int))\n",
    "    list_predict_foods = rdd_predict_foods.collect()\n",
    "if homeless_pre:\n",
    "    rdd_predict_homeless = df_no_homeless.rdd.map(lambda row: row[0]).zip(predict_homeless.map(int))\n",
    "    rdd_predict_homeless_trend = df_no_homeless.rdd.map(lambda row: row[0]).zip(predict_homeless_trend.map(int))\n",
    "    list_predict_homeless = rdd_predict_homeless.collect()\n",
    "    list_predict_homeless_trend = rdd_predict_homeless_trend.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform predicted rdd to dataframe and join it to original data that without food\n",
    "if food_pre:\n",
    "    df_predict_foods = spark.createDataFrame(list_predict_foods, schema=[\"id\",\"food_class\"])\n",
    "    df_no_food = df_no_food.drop('food_class')\n",
    "    concat_df_food = df_no_food.join(df_predict_foods, on='id')\n",
    "    \n",
    "if homeless_pre:\n",
    "    df_predict_homeless = spark.createDataFrame(list_predict_homeless, schema=[\"id\",\"homeless\"])\n",
    "    df_predict_homeless_trend = spark.createDataFrame(list_predict_homeless_trend, schema=[\"id\",\"homeless_trend\"])\n",
    "    \n",
    "    df_no_homeless = df_no_homeless.drop('homeless').drop('homeless_trend')\n",
    "    concat_df_homeless = df_no_homeless.join(df_predict_homeless, on='id').join(df_predict_homeless_trend, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-------------+------------+------------+--------+---------+---------+--------+--------------+----------+\n",
      "| id|               time|    timestamp|         lat|         lng|polarity|followers|following|homeless|homeless_trend|food_class|\n",
      "+---+-------------------+-------------+------------+------------+--------+---------+---------+--------+--------------+----------+\n",
      "|  0|21-12-2015 04:19:48|1.450631988E9|-37.82388645|145.06862749|     0.0|      136|      110|       4|            -9|         0|\n",
      "|  1|21-12-2015 08:43:20|  1.4506478E9|-37.81337025|144.96843006|     0.0|     2154|     2078|       4|            -9|         1|\n",
      "|  2|21-12-2015 08:43:20|  1.4506478E9|-37.81337025|144.96843006|     0.0|     2154|     2078|       4|            -9|         2|\n",
      "|  3|21-12-2015 08:43:20|  1.4506478E9|-37.81337025|144.96843006|     0.0|     2154|     2078|       4|            -9|         3|\n",
      "|  4|21-12-2015 08:43:20|  1.4506478E9|-37.81337025|144.96843006|     0.0|     2154|     2078|       4|            -9|         4|\n",
      "|  5|21-12-2015 11:17:03|1.450657023E9| -37.8187599| 144.9556732|  0.6249|       50|       48|       4|            -9|         4|\n",
      "|  6|21-12-2015 12:58:03|1.450663083E9|-37.76600978|144.98401132|  -0.296|     1346|     1023|       4|            -9|         5|\n",
      "|  7|21-12-2015 18:58:11|1.450684691E9|   -37.86511|   145.10127|  -0.296|      273|        1|       4|            -9|         6|\n",
      "|  8|22-12-2015 00:48:32|1.450705712E9|-37.81124367|144.96010321|  0.4588|      499|      254|       4|            -9|         7|\n",
      "|  9|22-12-2015 01:50:44|1.450709444E9| -37.8332176|  145.047348|  0.4404|      587|      631|       4|            -9|         8|\n",
      "| 10|22-12-2015 01:50:44|1.450709444E9| -37.8332176|  145.047348|  0.4404|      587|      631|       4|            -9|         9|\n",
      "| 11|22-12-2015 02:54:37|1.450713277E9|    -37.7998|     144.994|   0.126|      920|     2077|       4|            -9|         1|\n",
      "| 12|22-12-2015 03:28:25|1.450715305E9|-37.84016906|144.99552313|     0.0|      317|      472|       4|            -9|        10|\n",
      "| 13|22-12-2015 03:28:25|1.450715305E9|-37.84016906|144.99552313|     0.0|      317|      472|       4|            -9|        11|\n",
      "| 14|22-12-2015 03:43:31|1.450716211E9| -37.8558592|145.36530693|     0.0|      376|      506|       4|            -9|        12|\n",
      "| 15|22-12-2015 04:10:46|1.450717846E9| -37.8026085| 144.9475098|  0.6369|      629|      182|       4|            -9|        13|\n",
      "| 16|22-12-2015 04:10:46|1.450717846E9| -37.8026085| 144.9475098|  0.6369|      629|      182|       4|            -9|        14|\n",
      "| 17|22-12-2015 04:10:46|1.450717846E9| -37.8026085| 144.9475098|  0.6369|      629|      182|       4|            -9|        15|\n",
      "| 18|22-12-2015 04:10:46|1.450717846E9| -37.8026085| 144.9475098|  0.6369|      629|      182|       4|            -9|        14|\n",
      "| 19|22-12-2015 06:35:03|1.450726503E9| -37.8171692| 144.9649353|  0.5742|     1109|     1140|       4|            -9|        16|\n",
      "+---+-------------------+-------------+------------+------------+--------+---------+---------+--------+--------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_all_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11885\n",
      "+-------------------+------------+------------+--------+---------+---------+--------+--------------+---------+----------+\n",
      "|               time|         lat|         lng|polarity|followers|following|homeless|homeless_trend|     food|food_group|\n",
      "+-------------------+------------+------------+--------+---------+---------+--------+--------------+---------+----------+\n",
      "|21-12-2015 04:19:48|-37.82388645|145.06862749|     0.0|      136|      110|       4|            -9|     pork|      meat|\n",
      "|21-12-2015 08:43:20|-37.81337025|144.96843006|     0.0|     2154|     2078|       4|            -9|    lemon|    fruits|\n",
      "|21-12-2015 08:43:20|-37.81337025|144.96843006|     0.0|     2154|     2078|       4|            -9|     beef|      meat|\n",
      "|21-12-2015 08:43:20|-37.81337025|144.96843006|     0.0|     2154|     2078|       4|            -9|   ginger|vegetables|\n",
      "|21-12-2015 08:43:20|-37.81337025|144.96843006|     0.0|     2154|     2078|       4|            -9|   rocket|vegetables|\n",
      "|21-12-2015 11:17:03| -37.8187599| 144.9556732|  0.6249|       50|       48|       4|            -9|   rocket|vegetables|\n",
      "|21-12-2015 12:58:03|-37.76600978|144.98401132|  -0.296|     1346|     1023|       4|            -9|  chicken|      meat|\n",
      "|21-12-2015 18:58:11|   -37.86511|   145.10127|  -0.296|      273|        1|       4|            -9|  current|    fruits|\n",
      "|22-12-2015 00:48:32|-37.81124367|144.96010321|  0.4588|      499|      254|       4|            -9| mushroom|vegetables|\n",
      "|22-12-2015 01:50:44| -37.8332176|  145.047348|  0.4404|      587|      631|       4|            -9|    chips|  fastfood|\n",
      "|22-12-2015 01:50:44| -37.8332176|  145.047348|  0.4404|      587|      631|       4|            -9|    olive|vegetables|\n",
      "|22-12-2015 02:54:37|    -37.7998|     144.994|   0.126|      920|     2077|       4|            -9|    lemon|    fruits|\n",
      "|22-12-2015 03:28:25|-37.84016906|144.99552313|     0.0|      317|      472|       4|            -9| eggplant|vegetables|\n",
      "|22-12-2015 03:28:25|-37.84016906|144.99552313|     0.0|      317|      472|       4|            -9|vegetable|vegetables|\n",
      "|22-12-2015 03:43:31| -37.8558592|145.36530693|     0.0|      376|      506|       4|            -9|    pizza|  fastfood|\n",
      "|22-12-2015 04:10:46| -37.8026085| 144.9475098|  0.6369|      629|      182|       4|            -9|    apple|    fruits|\n",
      "|22-12-2015 04:10:46| -37.8026085| 144.9475098|  0.6369|      629|      182|       4|            -9|  avocado|    fruits|\n",
      "|22-12-2015 04:10:46| -37.8026085| 144.9475098|  0.6369|      629|      182|       4|            -9|   banana|    fruits|\n",
      "|22-12-2015 04:10:46| -37.8026085| 144.9475098|  0.6369|      629|      182|       4|            -9|  avocado|    fruits|\n",
      "|22-12-2015 06:35:03| -37.8171692| 144.9649353|  0.5742|     1109|     1140|       4|            -9|     crab|   seafood|\n",
      "+-------------------+------------+------------+--------+---------+---------+--------+--------------+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get food type according to food class\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "from keywords import Keywords\n",
    "\n",
    "generate_rev_dict()\n",
    "    \n",
    "# get food name by food class\n",
    "def get_food_type(food_class):\n",
    "    the_class = str(food_class)\n",
    "    if the_class in rev_dict.keys():\n",
    "        return rev_dict[the_class]\n",
    "    return None\n",
    "get_food_type_udf = udf(get_food_type, StringType())\n",
    "\n",
    "# get food group by food name\n",
    "def get_food_group(food):\n",
    "        if food in Keywords.fastfood:\n",
    "            return \"fastfood\"\n",
    "        if food in Keywords.fruits:\n",
    "            return \"fruits\"\n",
    "        if food in Keywords.grains:\n",
    "            return \"grains\"\n",
    "        if food in Keywords.meat:\n",
    "            return \"meat\"\n",
    "        if food in Keywords.seafood:\n",
    "            return \"seafood\"\n",
    "        if food in Keywords.vegetables:\n",
    "            return \"vegetables\"\n",
    "        return None\n",
    "get_food_group_udf = udf(get_food_group, StringType())\n",
    "\n",
    "df_all_info = df_all_info.withColumn('food', get_food_type_udf(df_all_info['food_class']))\n",
    "df_all_info = df_all_info.drop('food_class')\n",
    "\n",
    "# reform the dataframe to prepare for tranforming to json\n",
    "if food_pre:\n",
    "    concat_df_food = concat_df_food.withColumn('food', get_food_type_udf(concat_df_food['food_class']))\n",
    "    concat_df_food = concat_df_food.drop('food_class')\n",
    "\n",
    "    union_df = df_all_info.union(concat_df_food)\n",
    "else:\n",
    "    union_df = df_all_info\n",
    "    \n",
    "    \n",
    "if homeless_pre:\n",
    "    concat_df_homeless = concat_df_homeless.withColumn('food', get_food_type_udf(concat_df_homeless['food_class']))\n",
    "    concat_df_homeless = concat_df_homeless.drop('food_class')\n",
    "    \n",
    "    union_df = union_df.union(concat_df_homeless)\n",
    "\n",
    "    \n",
    "union_df = union_df.drop('id')\n",
    "union_df = union_df.drop('timestamp')\n",
    "\n",
    "union_df = union_df.withColumn('food_group', get_food_group_udf(union_df['food']))\n",
    "\n",
    "print(union_df.count())\n",
    "union_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = unioin_df.toJSON()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"time\":\"21-12-2015 04:19:48\",\"lat\":-37.82388645,\"lng\":145.06862749,\"polarity\":0.0,\"followers\":136,\"following\":110,\"homeless\":4,\"homeless_trend\":-9,\"food\":\"pork\",\"food_group\":\"meat\"}'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert success\n",
      "11885\n"
     ]
    }
   ],
   "source": [
    "# insert data into couchdb\n",
    "my_db = Couch('prediction11885')\n",
    "\n",
    "final_json = {}\n",
    "final_json[\"type\"] = \"FeatureCollection\"\n",
    "final_json[\"features\"] = []\n",
    "\n",
    "i = 0\n",
    "for row in json_data.collect():\n",
    "    #print(i)\n",
    "    entry = {}\n",
    "    entry[\"type\"] = \"Feature\"\n",
    "    entry[\"properties\"] = {}\n",
    "    entry[\"geometry\"] = {}\n",
    "    entry[\"geometry\"][\"type\"] = \"Point\"\n",
    "    entry[\"geometry\"][\"coordinates\"] = []\n",
    "    \n",
    "    json_obj = json.loads(row)\n",
    "    entry[\"properties\"][\"time\"] = json_obj[\"time\"]\n",
    "    entry[\"properties\"][\"polarity\"] = json_obj[\"polarity\"]\n",
    "    entry[\"properties\"][\"followers\"] = json_obj[\"followers\"]\n",
    "    entry[\"properties\"][\"following\"] = json_obj[\"following\"]\n",
    "    entry[\"properties\"][\"food\"] = json_obj[\"food\"]\n",
    "    entry[\"properties\"][\"food_group\"] = json_obj[\"food_group\"]\n",
    "    entry[\"properties\"][\"homeless\"] = json_obj[\"homeless\"]\n",
    "    entry[\"properties\"][\"homeless_trend\"] = json_obj[\"homeless_trend\"]\n",
    "    entry[\"geometry\"][\"coordinates\"].append(json_obj[\"lat\"])\n",
    "    entry[\"geometry\"][\"coordinates\"].append(json_obj[\"lng\"])\n",
    "    \n",
    "    final_json[\"features\"].append(entry)\n",
    "    i += 1\n",
    "my_db.insert(final_json)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
