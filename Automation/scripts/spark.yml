- hosts: analyser
  remote_user: ubuntu
  sudo: yes
  tasks:
    - name: Install JDK 1.8
      apt:
        name: openjdk-8-jre-headless
        update_cache: yes

    - name: Download Apache Spark 2.2.0
      get_url:
        url: http://apache.mirror.digitalpacific.com.au/spark/spark-2.2.0/spark-2.2.0-bin-hadoop2.7.tgz
        dest: /home/ubuntu/spark-2.2.0-bin-hadoop2.7.tgz

    - name: Unzip spark into /usr/local
      unarchive:
        src: /home/ubuntu/spark-2.2.0-bin-hadoop2.7.tgz
        dest: /usr/local
        remote_src: yes

    - name: Rename spark root folder to "spark"
      command: mv /usr/local/spark-2.2.0-bin-hadoop2.7 /usr/local/spark

    - name: Add permission to spark directory
      file: 
          path: /usr/local/spark
          owner: ubuntu
          group: ubuntu
          mode: 0777
          recurse: yes
          state: directory

    - name: Rename spark config file spark-env.sh
      command: mv /usr/local/spark/conf/spark-env.sh.template /usr/local/spark/conf/spark-env.sh

    - name: Add classpath to the end of /home/ubuntu/.bashrc
      lineinfile:
        dest: /home/ubuntu/.bashrc
        line: "{{ item }}"
        insertafter: EOF
      with_items:
        - 'export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64'
        - 'export SPARK_HOME=/usr/local/spark'
        - 'export PYSPARK_PYTHON=python3 ./bin/pyspark'
        - 'export PATH=$SPARK_HOME/bin:$PATH'
        - 'export PYTHONPATH=$SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.4-src.zip:$PYTHONPATH'

    - name: Activiate environment settings
      sudo : no
      shell: . /home/ubuntu/.bashrc

    - name: Install python dependencies with pip
      pip:
        name: numpy vaderSentiment shapely textblob httplib2 cloudant
        executable: pip3
